{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d131665f",
   "metadata": {},
   "source": [
    "# Garbage Classification Project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7085e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5424fe67",
   "metadata": {},
   "source": [
    "## Upload the Dataset ZIP file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c3b3a4",
   "metadata": {},
   "source": [
    "## Extract the ZIP File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7e024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"Garbage_dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"Garbage_dataset\")\n",
    "\n",
    "print(\"âœ… Dataset Extracted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14005f1a",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6212cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b06f5",
   "metadata": {},
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb2dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"Garbage_dataset/Garbage classification\"\n",
    "image_size = (150, 150)\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43256b2d",
   "metadata": {},
   "source": [
    "## Build the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ae2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1af8eb7",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=10, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7c1e54",
   "metadata": {},
   "source": [
    "## Plot Accuracy Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d2d558",
   "metadata": {},
   "source": [
    "## Predict a Custom Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad6d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c7bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=image_size)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    class_names = list(train_generator.class_indices.keys())\n",
    "    predicted_class = class_names[np.argmax(prediction)]\n",
    "    print(\"ðŸ“Œ Predicted Class:\", predicted_class)\n",
    "\n",
    "# predict_image(\"your_image.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b257727",
   "metadata": {},
   "source": [
    "## Save and Download the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e8d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"garbage_classifier_model.h5\")\n",
    "from google.colab import files\n",
    "files.download(\"garbage_classifier_model.h5\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
